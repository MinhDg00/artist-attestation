{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7b1a86-c7d7-44e1-b1e8-401285084b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud in /opt/conda/lib/python3.7/site-packages (0.34.0)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (2.2.1)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.3.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.6.0)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (3.19.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.54.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.0.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (2.21)\n",
      "Installing collected packages: google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: google-cloud-core\n",
      "    Found existing installation: google-cloud-core 2.2.3\n",
      "    Uninstalling google-cloud-core-2.2.3:\n",
      "      Successfully uninstalled google-cloud-core-2.2.3\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.2.1\n",
      "    Uninstalling google-cloud-storage-2.2.1:\n",
      "      Successfully uninstalled google-cloud-storage-2.2.1\n",
      "Successfully installed google-cloud-core-2.3.0 google-cloud-storage-2.3.0\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U google-cloud\n",
    "! pip install -U google-cloud-storage\n",
    "! pip install -U requests  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d57e27f-5e53-46a4-81b6-82b6be7660f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c905ab-f79f-449f-b034-60a9f0a1b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cs6384-bucket/info/\n",
      "gs://cs6384-bucket/sample_result/\n",
      "gs://cs6384-bucket/test/\n",
      "gs://cs6384-bucket/test_upload/\n",
      "gs://cs6384-bucket/train/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cs6384-bucket/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bcd94b6-c15c-45f2-97f7-6e01eaafa655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23819\n"
     ]
    }
   ],
   "source": [
    "# |test| = 23819\n",
    "!gsutil du gs://cs6384-bucket/test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a608149-5763-4705-8af4-c45edd57c451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79435\n"
     ]
    }
   ],
   "source": [
    "# |train} = 79435\n",
    "!gsutil du gs://cs6384-bucket/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a3d2a3-52d6-4155-8263-69ea7a721c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "!gsutil du gs://cs6384-bucket/info/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2415a5ce-4829-4b08-8f76-e53a5bb5cfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "!gsutil du gs://cs6384-bucket/sample_result | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a16baf2f-2946-4ae7-9ff8-49fd57de82e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jupyter/MOUNT_DIRECTORY’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/jupyter/MOUNT_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04d2a89-b062-4192-92ca-9e70fb80f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/05/01 14:37:36.347722 Start gcsfuse/0.40.0 (Go version go1.17.6) for app \"\" using mount point: /home/jupyter/MOUNT_DIRECTORY\n",
      "2022/05/01 14:37:36.360727 Opening GCS connection...\n",
      "2022/05/01 14:37:36.434567 Mounting file system \"cs6384-bucket\"...\n",
      "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running /usr/bin/fusermount: exit status 1\n"
     ]
    }
   ],
   "source": [
    "!gcsfuse --implicit-dirs cs6384-bucket /home/jupyter/MOUNT_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca19494f-6cf2-4ddd-91a9-8b4a05bd3b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info  sample_result  test  test_upload\ttrain\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jupyter/MOUNT_DIRECTORY/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3f59608e-da62-4c97-82dd-e9cb6955d815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install torch torchvision torchaudio torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "22a302a0-fcd5-419d-9161-cbd9dbf60089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d6f6e7ed-9546-469b-88d9-887b1dce9db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    date     genre  pixelsx  pixelsy  size_bytes   source  \\\n",
       "0  Barnett Newman  1955.0  abstract  15530.0   6911.0   9201912.0  wikiart   \n",
       "1  Barnett Newman  1950.0  abstract  14559.0   6866.0   8867532.0  wikiart   \n",
       "2     kiri nichol  2013.0       NaN   9003.0   9004.0   1756681.0      NaN   \n",
       "3     kiri nichol  2013.0       NaN   9003.0   9004.0   1942046.0      NaN   \n",
       "4     kiri nichol  2013.0       NaN   9003.0   9004.0   1526212.0      NaN   \n",
       "\n",
       "                  style                  title artist_group  in_train  \\\n",
       "0  Color Field Painting                  Uriel   train_only      True   \n",
       "1  Color Field Painting  Vir Heroicus Sublimis   train_only      True   \n",
       "2         Neoplasticism                    NaN    test_only     False   \n",
       "3         Neoplasticism                    NaN    test_only     False   \n",
       "4         Neoplasticism                    NaN    test_only     False   \n",
       "\n",
       "  new_filename  \n",
       "0   102257.jpg  \n",
       "1    75232.jpg  \n",
       "2    32145.jpg  \n",
       "3    20304.jpg  \n",
       "4      836.jpg  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA_PATH = '/home/jupyter/MOUNT_DIRECTORY/info'\n",
    "TRAIN_PATH = '/home/jupyter/MOUNT_DIRECTORY/train'\n",
    "TEST_PATH = '/home/jupyter/MOUNT_DIRECTORY/test'\n",
    "\n",
    "artdf = pd.read_csv(os.path.join(METADATA_PATH, 'all_data_info.csv'))\n",
    "artdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "efe70026-6103-48ae-bba9-665f74be8d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17214"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only artists with more than 300 paintings and balance them out\n",
    "\n",
    "datadf = artdf.groupby(\"artist\").filter(lambda x: len(x) >= 300)\n",
    "g = datadf.groupby('artist')\n",
    "datadf = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "datadf = datadf.drop(columns=['date'])\n",
    "len(datadf)\n",
    "\n",
    "# |dataset| = 17214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "80a6ce04-e02e-42ed-892e-2207fef6f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>new_filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>in_train</th>\n",
       "      <th>artist_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Albert Bierstadt</th>\n",
       "      <th>0</th>\n",
       "      <td>44683.jpg</td>\n",
       "      <td>Albert Bierstadt</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45374.jpg</td>\n",
       "      <td>Albert Bierstadt</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672.jpg</td>\n",
       "      <td>Albert Bierstadt</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32818.jpg</td>\n",
       "      <td>Albert Bierstadt</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26808.jpg</td>\n",
       "      <td>Albert Bierstadt</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   new_filename            artist  in_train  artist_idx\n",
       "artist                                                                 \n",
       "Albert Bierstadt 0    44683.jpg  Albert Bierstadt     False           0\n",
       "                 1    45374.jpg  Albert Bierstadt      True           0\n",
       "                 2      672.jpg  Albert Bierstadt      True           0\n",
       "                 3    32818.jpg  Albert Bierstadt      True           0\n",
       "                 4    26808.jpg  Albert Bierstadt      True           0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert artist names into label indexes\n",
    "artist = datadf[['new_filename','artist','in_train']]\n",
    "artist['artist'] = artist['artist'].astype('category')\n",
    "artist['artist_idx'] = artist['artist'].cat.codes\n",
    "artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "69f88e62-125f-4d7a-81ab-c0243711c9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     13216\n",
       "False     3998\n",
       "Name: in_train, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist['in_train'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "65e3b113-43d9-4338-8a2e-d5c7b55febb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13216\n",
      "3998\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "train_df = artist[artist['in_train'] == True]\n",
    "test_df = artist[artist['in_train'] == False]\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "67a4d3bb-a7e2-43b5-ab5b-51aa02076069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Class. Uses torch.utils.data.Dataset\n",
    "\n",
    "class ImageProcessor(Dataset):\n",
    "\n",
    "    def __init__(self, path, metadata_df, mode = 'RGB', is_train = True, crop_width = 224, crop_height = 224):\n",
    "        self.path = path\n",
    "        self.mode = mode\n",
    "        self.metadata_df = metadata_df\n",
    "        self.X,self.y = self.read_input(self.path)\n",
    "        self.is_train = is_train\n",
    "        self.crop_width = crop_width\n",
    "        self.crop_height = crop_height\n",
    "        \n",
    "\n",
    "    # A simple function to get the file paths of all the training images and their corresponding labels\n",
    "    def read_input(self,path):\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            _, filename = os.path.split(path)\n",
    "            label = self.metadata_df[self.metadata_df['new_filename'] == filename, 'artist_idx'].iloc[0]\n",
    "            return [path],[label]\n",
    "\n",
    "        elif os.path.isdir(path):\n",
    "            paths = []\n",
    "            labels = []\n",
    "            for i, df in self.metadata_df.iterrows():\n",
    "                image = df['new_filename']\n",
    "                img_path = os.path.join(path,image)\n",
    "                label = df['artist_idx']\n",
    "                paths.append(img_path)\n",
    "                labels.append(label)\n",
    "            return paths,labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        # Fetch image path and label\n",
    "        path = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        # Convert to BGR if necessary\n",
    "        if self.mode == 'BGR':\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Preprocess image\n",
    "        crop = self.preprocess(img)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        crop = crop.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(crop), torch.Tensor([int(label)])\n",
    "    \n",
    "    # Image preprocessing for a single image\n",
    "    def preprocess(self,img):\n",
    "        \n",
    "        image = img\n",
    "        \n",
    "        # STEP 1: Zero-Centering and Normalization\n",
    "\n",
    "        # Normalize pixels\n",
    "        image = image / 255\n",
    "\n",
    "        # Zero center pixels across the image for each channel\n",
    "        means = np.mean(image,axis = (0,1))\n",
    "        image[:,:,0] = image[:,:,0] - means[0]\n",
    "        image[:,:,1] = image[:,:,1] - means[1]\n",
    "        image[:,:,2] = image[:,:,2] - means[2]\n",
    "\n",
    "        # STEP 2: get crop of image\n",
    "        \n",
    "        cw = self.crop_width\n",
    "        ch = self.crop_height\n",
    "        \n",
    "        # Cropping for training set\n",
    "        if self.is_train:\n",
    "\n",
    "            # Randomly flip image with a 50% chance\n",
    "            choose = [0,1]\n",
    "            hf = random.choices(choose, weights = [0.5,0.5], k = 1)\n",
    "            if hf[0] == 1:\n",
    "                image = cv2.flip(image , 1)\n",
    "\n",
    "            # Get random (crop_width X crop_height) crop of image\n",
    "            max_h = image.shape[0] - ch\n",
    "            max_w = image.shape[1] - cw\n",
    "            x = np.random.randint(0, max_w)\n",
    "            y = np.random.randint(0, max_h)\n",
    "            crop = image[y: y + ch, x: x + cw]\n",
    "        \n",
    "        # Cropping for test and validation set\n",
    "        else:\n",
    "            \n",
    "            # Get a center crop of the image\n",
    "            center = np.array(list(image.shape)) / 2\n",
    "            mid_h = center[0] - ch/2\n",
    "            mid_w = center[1] - cw/2\n",
    "            crop = image[int(mid_h):int(mid_h + ch), int(mid_w):int(mid_w + cw)]\n",
    "\n",
    "        return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "edec875f-46ef-44a1-bdcc-4088cb49e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13216\n",
      "3998\n"
     ]
    }
   ],
   "source": [
    "# Create train and test dataset processors\n",
    "train_dataset = ImageProcessor(TRAIN_PATH,train_df)\n",
    "test_dataset = ImageProcessor(TEST_PATH,test_df,is_train = False)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "167a37d7-6dbd-4583-8305-c5be27803db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test Dataloaders\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset,  batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
    "test_loader = DataLoader(test_dataset,  batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8a4eda46-8c8b-470f-b6a5-7215ad95ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Baseline Convolutional Neural Network\n",
    "class BaselineConvnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride = 2, padding = 1)\n",
    "        nn.init.zeros_(self.conv1.bias) \n",
    "        nn.init.normal_(self.conv1.weight, mean = 0, std = (math.sqrt(2/(32*3*3))))\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.batch_norm2d = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride = 2, padding = 1)\n",
    "        nn.init.zeros_(self.conv2.bias) \n",
    "        nn.init.normal_(self.conv2.weight, mean = 0, std = (math.sqrt(2/(32*3*3))))\n",
    "        \n",
    "        self.batch_norm1d = nn.BatchNorm1d(228)\n",
    "        self.fc1 = nn.Linear(6272, 228)\n",
    "        self.fc2 = nn.Linear(228, 57)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution stack 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm2d(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Convolution stack 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2d(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten and FC layers\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = self.batch_norm1d(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "02746d2e-367b-431f-8e03-2479c43d0c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "         MaxPool2d-3           [-1, 32, 56, 56]               0\n",
      "            Conv2d-4           [-1, 32, 28, 28]           9,248\n",
      "       BatchNorm2d-5           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-6           [-1, 32, 14, 14]               0\n",
      "            Linear-7                  [-1, 228]       1,430,244\n",
      "       BatchNorm1d-8                  [-1, 228]             456\n",
      "            Linear-9                   [-1, 57]          13,053\n",
      "================================================================\n",
      "Total params: 1,454,025\n",
      "Trainable params: 1,454,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 7.33\n",
      "Params size (MB): 5.55\n",
      "Estimated Total Size (MB): 13.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BaselineConvnet()\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2fb7c-b4ee-40de-88c9-ef3a0a3ec15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,epochs = 2, lr = 0.001, beta_1 = 0.9, beta_2 = 0.999):\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr, betas = (beta_1,beta_2))\n",
    "    \n",
    "    for e in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = inputs.shape[0]\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            print(f'[{e + 1}, {i * batch_size:5d}] loss: {running_loss / batch_size:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
